{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "638976bf-8d03-4e81-9732-de05d0fab659",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = \"v7.0.0\"\n",
    "calc_mode = \"crystal_u0_plus_d3\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cac7da-2638-482d-9bd7-b1a1d79b65cb",
   "metadata": {},
   "source": [
    "## 1. Initial structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "335dbf49-0daa-42e0-8925-898eaf7ce740",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from ase.io import read\n",
    "from pfcc_extras.structure.ase_rdkit_converter import atoms_to_smiles\n",
    "from pfcc_extras.liquidgenerator.liquid_generator import LiquidGenerator\n",
    "from density import estimate_density\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def make_polyIL_structure(mol_type, n_mol):\n",
    "    assert mol_type in [\"monomer\", \"dimer\", \"trimer\", \"polymer\", \"polymer_x7\"]\n",
    "\n",
    "    monomer = read(f\"assets/monomer.xyz\")\n",
    "    polymer = read(f\"assets/{mol_type}.xyz\")\n",
    "    anion = read(\"assets/PF6.xyz\")\n",
    "    if mol_type == \"monomer\":\n",
    "        n_anion = n_mol\n",
    "    elif mol_type == \"dimer\":\n",
    "        n_anion = n_mol * 2\n",
    "    elif mol_type == \"trimer\":\n",
    "        n_anion = n_mol * 3\n",
    "    elif mol_type == \"polymer\":\n",
    "        n_anion = n_mol * 5\n",
    "    else:\n",
    "        n_anion = n_mol * 7\n",
    "    \n",
    "    polymer.positions -= polymer.get_center_of_mass()\n",
    "    anion.positions -= anion.get_center_of_mass()\n",
    "    \n",
    "    # Estimate density for the polymer based on its SMILES conversion.\n",
    "    density = estimate_density(atoms_to_smiles(monomer))\n",
    "    \n",
    "    # Create a mixture of polymer frames and anions.\n",
    "    composition = [polymer] * n_mol + [anion] * n_anion\n",
    "    \n",
    "    # Generate a bulk random structure using the LiquidGenerator.\n",
    "    liquid_generator = LiquidGenerator(engine=\"torch\", composition=composition, density=density, cubic=True)\n",
    "    atoms = liquid_generator.run(epochs=100)\n",
    "    clear_output()\n",
    "    return atoms\n",
    "\n",
    "\n",
    "# Create a directory to store the generated initial structures.\n",
    "structure_dir = Path(\"structures\")\n",
    "structure_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "initial_structures = []\n",
    "\n",
    "for n_mol in [6, 12]:    \n",
    "    filename = f\"monomer_{n_mol}.xyz\"\n",
    "    filepath = structure_dir / filename\n",
    "    if not filepath.is_file():\n",
    "        atoms = make_polyIL_structure(\"monomer\", n_mol)\n",
    "        atoms.write(filepath)\n",
    "    else:\n",
    "        atoms = read(filepath)\n",
    "    initial_structures.append(atoms)\n",
    "\n",
    "for n_mol in [3, 6]:    \n",
    "    filename = f\"dimer_{n_mol}.xyz\"\n",
    "    filepath = structure_dir / filename\n",
    "    if not filepath.is_file():\n",
    "        atoms = make_polyIL_structure(\"dimer\", n_mol)\n",
    "        atoms.write(filepath)\n",
    "    else:\n",
    "        atoms = read(filepath)\n",
    "    initial_structures.append(atoms)\n",
    "\n",
    "for n_mol in [2, 3]:    \n",
    "    filename = f\"trimer_{n_mol}.xyz\"\n",
    "    filepath = structure_dir / filename\n",
    "    if not filepath.is_file():\n",
    "        atoms = make_polyIL_structure(\"trimer\", n_mol)\n",
    "        atoms.write(filepath)\n",
    "    else:\n",
    "        atoms = read(filepath)\n",
    "    initial_structures.append(atoms)\n",
    "\n",
    "for n_mol in [2, 3]:    \n",
    "    filename = f\"polymer_{n_mol}.xyz\"\n",
    "    filepath = structure_dir / filename\n",
    "    if not filepath.is_file():\n",
    "        atoms = make_polyIL_structure(\"polymer\", n_mol)\n",
    "        atoms.write(filepath)\n",
    "    else:\n",
    "        atoms = read(filepath)\n",
    "    initial_structures.append(atoms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3855d2-70f7-4831-bd52-70e664354bcd",
   "metadata": {},
   "source": [
    "## 2. Initial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118da5ff-528e-4578-8cee-ff4c1b5e2bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset file init_dataset/init.h5 and starting sampling.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "772765a0a33c472288d138a6f7f58acd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Total progress: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from h5py import File\n",
    "from tqdm.auto import tqdm\n",
    "from concurrent.futures import as_completed, ThreadPoolExecutor\n",
    "\n",
    "from pfp_api_client import Estimator, ASECalculator\n",
    "from light_pfp_data.utils.dataset import H5DatasetWriter\n",
    "from light_pfp_data.sample.crystal import sample_md, sample_rattle\n",
    "\n",
    "\n",
    "# Create folder for the initial dataset\n",
    "init_dataset_dir = Path(\"init_dataset\")\n",
    "init_dataset_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Define the initial dataset file\n",
    "initial_dataset_file = init_dataset_dir / \"init.h5\"\n",
    "\n",
    "if initial_dataset_file.exists():\n",
    "    print(f\"Dataset file {initial_dataset_file} already exists. Skipping dataset generation.\")\n",
    "    dataset = H5DatasetWriter(File(initial_dataset_file, \"r+\"))\n",
    "else:\n",
    "    print(f\"Creating dataset file {initial_dataset_file} and starting sampling.\")\n",
    "    dataset = H5DatasetWriter(initial_dataset_file)\n",
    "\n",
    "    # Initialize the PFP estimator and calculator\n",
    "    estimator = Estimator(model_version=model_version, calc_mode=calc_mode)\n",
    "    calc = ASECalculator(estimator)\n",
    "\n",
    "    # List to store our future tasks\n",
    "    futures = []\n",
    "    pbar = tqdm(desc=\"Total progress\", total=0, leave=True)\n",
    "\n",
    "    # Use ThreadPoolExecutor for multithreading sampling tasks\n",
    "    with ThreadPoolExecutor(max_workers=16) as executor:\n",
    "        for atoms in initial_structures:\n",
    "            futures += sample_md(\n",
    "                input_structure=atoms,\n",
    "                calculator=calc,\n",
    "                dataset=dataset,\n",
    "                supercell=(1, 1, 1),\n",
    "                sampling_temp=[500.0, 1000.0, 1500.0],\n",
    "                sampling_steps=[5000, 5000, 5000],\n",
    "                sampling_interval=[100, 100, 100],\n",
    "                ensemble=\"nvt\",\n",
    "                executor=executor,\n",
    "                pbar=pbar\n",
    "            )\n",
    "            futures += sample_md(\n",
    "                input_structure=atoms,\n",
    "                calculator=calc,\n",
    "                dataset=dataset,\n",
    "                supercell=(1, 1, 1),\n",
    "                sampling_temp=[400.0, 500.0, 600.0],\n",
    "                sampling_pressure=[1.0, 1.0, 1.0],\n",
    "                sampling_steps=[5000, 5000, 5000],\n",
    "                sampling_interval=[100, 100, 100],\n",
    "                ensemble=\"npt\",\n",
    "                executor=executor,\n",
    "                pbar=pbar\n",
    "            )\n",
    "            futures += sample_rattle(\n",
    "                input_structure=atoms,\n",
    "                calculator=calc,\n",
    "                dataset=dataset,\n",
    "                stdev=0.1,\n",
    "                n_sample=10,\n",
    "                supercell=(1, 1, 1)\n",
    "            )\n",
    "            futures += sample_rattle(\n",
    "                input_structure=atoms,\n",
    "                calculator=calc,\n",
    "                dataset=dataset,\n",
    "                stdev=0.15,\n",
    "                n_sample=10,\n",
    "                supercell=(1, 1, 1)\n",
    "            )\n",
    "\n",
    "    for f in as_completed(futures):\n",
    "        _ = f.result()\n",
    "\n",
    "dataset.h5.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226e5f68-dbdb-4e30-975c-ae43b7ab7c23",
   "metadata": {},
   "source": [
    "## 3. Active learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda15f52-e015-492f-80fa-161441c33dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from light_pfp_autogen.active_learning import ActiveLearning\n",
    "from light_pfp_autogen.config import ActiveLearningConfig, TrainConfig, SampleConfig, CommonConfig, MTPConfig\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Set hyperparameters for the active learning task\n",
    "active_learning_config = ActiveLearningConfig(\n",
    "    task_name=\"polyIL_diffusion\",\n",
    "    pfp_model_version=model_version,\n",
    "    pfp_calc_mode=calc_mode,\n",
    "    init_dataset=[\"init_dataset/init.h5\"],\n",
    "    work_dir=\"./autogen_workdir\",\n",
    "    training_time=0.5,\n",
    "    train_config=TrainConfig(\n",
    "        common_config=CommonConfig(max_forces=50.0, max_energy=5.0),\n",
    "        mtp_config=MTPConfig(pretrained_model=\"ORGANIC_SMALL_NN\")\n",
    "    ),\n",
    "    sample_config=SampleConfig(\n",
    "        dE_min_coef=3.0,\n",
    "        dE_max_coef=20.0,\n",
    "        dF_min_coef=10.0,\n",
    "        dF_max=50.0,\n",
    "        dS_min_coef=3.0,\n",
    "        dS_max_coef=20.0,\n",
    "        pfp_fallback_samples=5\n",
    "    )\n",
    ")\n",
    "\n",
    "# Initialize the active learning task\n",
    "active_learning = ActiveLearning(active_learning_config)\n",
    "\n",
    "# Start the initial training and active learning process\n",
    "active_learning.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7793b71-af15-42e9-8796-836bb5b2244b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  iter    n_items    n_collected    n_context    n_error    n_max_sample     E_error    F_error      S_error\n",
      "------  ---------  -------------  -----------  ---------  --------------  ----------  ---------  -----------\n",
      "     0       1360           1360           10          0              10  0.012811      1.57252  0.00129418\n",
      "     1       2222            712           10          0               6  0.00291231    1.21913  0.00067769\n",
      "     2       2628            407           10          0               5  0.00129946    1.00878  0.000612832\n",
      "     3       2405            705           10          0               5  0.00135669    1.10198  0.000762934\n",
      "     4       1975           1147           10          0               9  0.0032764     1.40298  0.000603046\n",
      "     5       1974           1156           10          0               9  0.00416708    1.41927  0.000730803\n",
      "     6       2473            758           10          0               6  0.00634993    1.18043  0.000807921\n",
      "     7       2441            481           10          0               5  0.00529605    1.12389  0.000760097\n",
      "     8       2639            436           10          0               5  0.00393113    1.06654  0.000777804\n",
      "     9       2423            560           10          0               6  0.00459456    1.19279  0.00080329\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from ase import units\n",
    "from ase.md.langevin import Langevin\n",
    "from ase.md.npt import NPT\n",
    "from ase.md.velocitydistribution import MaxwellBoltzmannDistribution\n",
    "from IPython.display import clear_output\n",
    "from light_pfp_autogen.context import DataCollectionContext\n",
    "\n",
    "\n",
    "# Define the MD simulation protocol for active learning iterations tailored to polyIL diffusion task.\n",
    "def active_learning_protocol(size, steps):\n",
    "    temperature = np.random.uniform(300, 700)  # K\n",
    "    atoms = make_polyIL_structure(\"polymer_x7\", 4)\n",
    "    \n",
    "    print(f\"Running MD for polyIL with size={len(atoms)}, temperature={temperature:.1f} K\")\n",
    "    MaxwellBoltzmannDistribution(atoms, temperature_K=temperature)\n",
    "    \n",
    "    # First stage: Short NVT MD using Langevin thermostat for equilibration.\n",
    "    md_nvt = Langevin(atoms, units.fs, temperature_K=temperature, friction=0.1)\n",
    "    with DataCollectionContext(md=md_nvt, interval=100, max_samples=20):\n",
    "        md_nvt.run(steps=5000)  # short equilibration run\n",
    "    \n",
    "    # Second stage: Longer NPT MD to generate diverse training data.\n",
    "    md_npt = NPT(\n",
    "        atoms,\n",
    "        units.fs,\n",
    "        temperature_K=temperature,\n",
    "        externalstress=1 * units.bar,\n",
    "        ttime=20.0 * units.fs,\n",
    "        pfactor=2e6 * units.GPa * (units.fs**2)\n",
    "    )\n",
    "    with DataCollectionContext(md=md_npt, interval=100, max_samples=steps // 100 // 2):\n",
    "        md_npt.run(steps=steps)\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "\n",
    "\n",
    "for i in range(active_learning.iter, 10):\n",
    "    print(f\"Current active learning iteration: {i} (small structures)\")\n",
    "    for _ in range(5):\n",
    "        active_learning_protocol(size=\"small\", steps=50000)\n",
    "    active_learning.update()\n",
    "\n",
    "active_learning.print_md_statistics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c179ebb-7a0e-48e1-933a-44eb4cd17b36",
   "metadata": {},
   "source": [
    "## 4. Post training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b53276-3bb2-4f88-97b1-58ffa2f434d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from light_pfp_autogen.utils import submit_training_job, check_training_job_status, estimate_epoch\n",
    "\n",
    "epoch = estimate_epoch(active_learning.datasets_list, 2)\n",
    "train_config_dict = {\n",
    "    \"common_config\": {\n",
    "        \"total_epoch\": epoch,\n",
    "        \"max_forces\": 50.0\n",
    "    },\n",
    "    \"mtp_config\": {\n",
    "        \"pretrained_model\": \"ORGANIC_SMALL_NN\"\n",
    "    },\n",
    "}\n",
    "\n",
    "training_config = TrainConfig.from_dict(\n",
    "    train_config_dict\n",
    ")\n",
    "\n",
    "model_id = submit_training_job(\n",
    "    training_config,\n",
    "    active_learning.datasets_list,\n",
    "    \"polyIL_diffusion_final\",\n",
    ")\n",
    "\n",
    "status = check_training_job_status(model_id)\n",
    "print(f\"Training job {model_id} status: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558f1a63-7239-4fd7-b885-86e04927f407",
   "metadata": {},
   "source": [
    "## 5. PFP validation run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8783b542-0d16-4f0b-a04a-a13174ac981c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ase import units\n",
    "from ase.io import read, Trajectory\n",
    "from ase.md.velocitydistribution import MaxwellBoltzmannDistribution\n",
    "from ase.md.langevin import Langevin\n",
    "from ase.md.npt import NPT\n",
    "\n",
    "\n",
    "def md_protocol(atoms, temperature, steps, traj):\n",
    "    print(f\"Running MD for polyIL with size={len(atoms)}, temperature={temperature:.1f} K\")\n",
    "    MaxwellBoltzmannDistribution(atoms, temperature_K=temperature)\n",
    "\n",
    "    traj = Trajectory(traj, \"w\", atoms=atoms)\n",
    "    # First stage: Short NVT MD using Langevin thermostat for equilibration.\n",
    "    md_nvt = Langevin(atoms, units.fs, temperature_K=temperature, friction=0.1)\n",
    "    md_nvt.attach(traj.write, interval=100)\n",
    "    md_nvt.run(steps=5000)  # short equilibration run\n",
    "    \n",
    "    # Second stage: Longer NPT MD to generate diverse training data.\n",
    "    md_npt = NPT(\n",
    "        atoms,\n",
    "        units.fs,\n",
    "        temperature_K=temperature,\n",
    "        mask=np.eye(3),\n",
    "        externalstress=1 * units.bar,\n",
    "        ttime=20.0 * units.fs,\n",
    "        pfactor=2e6 * units.GPa * (units.fs**2)\n",
    "    )\n",
    "    md_npt.attach(traj.write, interval=100)\n",
    "    md_npt.run(steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddad154-a06a-4453-ac1c-6c04e69114e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "md_dir = Path(\"pfp_md\")\n",
    "md_dir.mkdir(exist_ok=True)\n",
    "\n",
    "def md_wrap(t):\n",
    "    calc = ASECalculator(Estimator(model_version=model_version, calc_mode=calc_mode))\n",
    "    atoms = read(\"assets/md_init.xyz\")\n",
    "    atoms.calc = calc\n",
    "    traj = md_dir / f\"md_{t}.traj\"\n",
    "    md_protocol(atoms, t, 50000, traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a6eede-e138-4b5a-9976-1d9c239ded82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "Parallel(n_jobs=3)(delayed(md_wrap)(t) for t in [400, 500, 600])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6971810-a6c5-4826-956e-a2e84eed0112",
   "metadata": {},
   "source": [
    "## 6. LightPFP validation run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3290e3a5-1ab1-4684-b6e9-254f8471d49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ase import units\n",
    "from ase.io import read, Trajectory\n",
    "from ase.md.velocitydistribution import MaxwellBoltzmannDistribution\n",
    "from ase.md.langevin import Langevin\n",
    "from ase.md.npt import NPT\n",
    "\n",
    "\n",
    "def md_protocol(atoms, temperature, steps, traj):\n",
    "    print(f\"Running MD for polyIL with size={len(atoms)}, temperature={temperature:.1f} K\")\n",
    "    MaxwellBoltzmannDistribution(atoms, temperature_K=temperature)\n",
    "\n",
    "    traj = Trajectory(traj, \"w\", atoms=atoms)\n",
    "    # First stage: Short NVT MD using Langevin thermostat for equilibration.\n",
    "    md_nvt = Langevin(atoms, units.fs, temperature_K=temperature, friction=0.1)\n",
    "    md_nvt.attach(traj.write, interval=100)\n",
    "    md_nvt.run(steps=5000)  # short equilibration run\n",
    "    \n",
    "    # Second stage: Longer NPT MD to generate diverse training data.\n",
    "    md_npt = NPT(\n",
    "        atoms,\n",
    "        units.fs,\n",
    "        temperature_K=temperature,\n",
    "        mask=np.eye(3),\n",
    "        externalstress=1 * units.bar,\n",
    "        ttime=20.0 * units.fs,\n",
    "        pfactor=2e6 * units.GPa * (units.fs**2)\n",
    "    )\n",
    "    md_npt.attach(traj.write, interval=100)\n",
    "    md_npt.run(steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800cede6-86fa-47e1-8a96-ffec3388f380",
   "metadata": {},
   "outputs": [],
   "source": [
    "from light_pfp_client import Estimator, ASECalculator\n",
    "\n",
    "calc = ASECalculator(Estimator(model_id = model_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a805bfc9-6111-4db2-acbd-2790b3301733",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "md_dir = Path(\"light_pfp_md\")\n",
    "md_dir.mkdir(exist_ok=True)\n",
    "\n",
    "for t in [400, 500, 600]:\n",
    "    atoms = read(\"assets/md_init.xyz\")\n",
    "    atoms.calc = calc\n",
    "    traj = md_dir / f\"md_{t}.traj\"\n",
    "    md_protocol(atoms, t, 50000, traj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b718bbe-5902-44a3-9486-2a6bb0160368",
   "metadata": {},
   "source": [
    "### 6.1 Analysis of results\n",
    "#### A. Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992b46a3-6c99-4b24-b959-a82b5962adb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ase import units\n",
    "from ase.io import Trajectory\n",
    "\n",
    "def get_density(atoms):\n",
    "    return atoms.get_masses().sum() / units.kg / atoms.get_volume() * 1e27\n",
    "\n",
    "def get_density_traj(traj, last_n_frames=100):\n",
    "    return np.mean([get_density(atoms) for atoms in traj[-last_n_frames:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e821a28-367e-49d7-9708-cfc1cf85c2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "pfp_density_400 = [get_density(atoms) for atoms in Trajectory(\"pfp_md/md_400.traj\")]\n",
    "pfp_density_500 = [get_density(atoms) for atoms in Trajectory(\"pfp_md/md_500.traj\")]\n",
    "pfp_density_600 = [get_density(atoms) for atoms in Trajectory(\"pfp_md/md_600.traj\")]\n",
    "lpfp_density_400 = [get_density(atoms) for atoms in Trajectory(\"light_pfp_md/md_400.traj\")]\n",
    "lpfp_density_500 = [get_density(atoms) for atoms in Trajectory(\"light_pfp_md/md_500.traj\")]\n",
    "lpfp_density_600 = [get_density(atoms) for atoms in Trajectory(\"light_pfp_md/md_600.traj\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939426b9-7e4e-4de3-aa16-6a40c089a4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(pfp_density_400))*0.1, pfp_density_400, label=\"PFP 400K\", c=\"r\")\n",
    "plt.plot(np.arange(len(lpfp_density_400))*0.1, lpfp_density_400, label=\"LightPFP 400K\", c=\"r\", linestyle=\"--\")\n",
    "plt.plot(np.arange(len(pfp_density_500))*0.1, pfp_density_500, label=\"PFP 500K\", c=\"b\")\n",
    "plt.plot(np.arange(len(lpfp_density_500))*0.1, lpfp_density_500, label=\"LightPFP 500K\", c=\"b\", linestyle=\"--\")\n",
    "plt.plot(np.arange(len(pfp_density_600))*0.1, pfp_density_600, label=\"PFP 600K\", c=\"g\")\n",
    "plt.plot(np.arange(len(lpfp_density_600))*0.1, lpfp_density_600, label=\"LightPFP 600K\", c=\"g\", linestyle=\"--\")\n",
    "plt.xlabel(\"time (ps\")\n",
    "plt.ylabel(\"density (g/cm^3)\")\n",
    "plt.legend()\n",
    "plt.savefig(\"density.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71d7c6e-8934-46b5-adf2-7decbef2c4a1",
   "metadata": {},
   "source": [
    "#### B. RDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4feca85-0429-46c9-b9b9-15c5c2cd9328",
   "metadata": {},
   "outputs": [],
   "source": [
    "from light_pfp_evaluate.md import plot_rdf\n",
    "from ase.io import Trajectory\n",
    "\n",
    "for t in [400, 500, 600]:\n",
    "    plot_rdf(\n",
    "        [t],\n",
    "        [Trajectory(f\"pfp_md/md_{t}.traj\")[-100:]],\n",
    "        [Trajectory(f\"light_pfp_md/md_{t}.traj\")[-100:]],\n",
    "        f\"rdf_{t}.png\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca962eff-984d-448f-9edb-c5f1b4532d20",
   "metadata": {},
   "source": [
    "#### C. MSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4663392-7329-453f-a4ef-4ba48a53468a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_msd(traj):\n",
    "    numbers = traj[0].get_atomic_numbers()\n",
    "    ind = (numbers==6) | (numbers==7) | (numbers==1)\n",
    "    pos = np.array([atoms[numbers==15].get_positions() for atoms in traj])\n",
    "    msd = [np.mean(np.sum((pos[i+1:] - pos[:-(i+1)])**2, axis=2)) for i in range(len(pos)-1)]\n",
    "    return msd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99714f1c-2579-4a0e-a278-13ca00a68767",
   "metadata": {},
   "outputs": [],
   "source": [
    "pfp_msd_400 = get_msd(Trajectory(\"pfp_md/md_400.traj\")[200:])\n",
    "pfp_msd_500 = get_msd(Trajectory(\"pfp_md/md_500.traj\")[200:])\n",
    "pfp_msd_600 = get_msd(Trajectory(\"pfp_md/md_600.traj\")[200:])\n",
    "lpfp_msd_400 = get_msd(Trajectory(\"light_pfp_md/md_400.traj\")[200:])\n",
    "lpfp_msd_500 = get_msd(Trajectory(\"light_pfp_md/md_500.traj\")[200:])\n",
    "lpfp_msd_600 = get_msd(Trajectory(\"light_pfp_md/md_600.traj\")[200:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32b86cc-0546-46de-b71e-e4e351aeb704",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(pfp_msd_400))*0.1, pfp_msd_400, label=\"PFP 400K\", c=\"r\")\n",
    "plt.plot(np.arange(len(lpfp_msd_400))*0.1, lpfp_msd_400, label=\"LightPFP 400K\", c=\"r\", linestyle=\"--\")\n",
    "plt.plot(np.arange(len(pfp_msd_500))*0.1, pfp_msd_500, label=\"PFP 500K\", c=\"b\")\n",
    "plt.plot(np.arange(len(lpfp_msd_500))*0.1, lpfp_msd_500, label=\"LightPFP 500K\", c=\"b\", linestyle=\"--\")\n",
    "plt.plot(np.arange(len(pfp_msd_600))*0.1, pfp_msd_600, label=\"PFP 600K\", c=\"g\")\n",
    "plt.plot(np.arange(len(lpfp_msd_600))*0.1, lpfp_msd_600, label=\"LightPFP 600K\", c=\"g\", linestyle=\"--\")\n",
    "plt.xlabel(\"time (ps)\")\n",
    "plt.ylabel(\"msd\")\n",
    "plt.legend()\n",
    "plt.savefig(\"msd.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89a2ff4-07e4-46b7-b433-9d79a5e75287",
   "metadata": {},
   "source": [
    "#### D. Diffusion active energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48cc770-fbac-4129-b5fd-8e99862321dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diffusion_coef(msd, time_interval):\n",
    "    time = np.arange(len(msd)) * time_interval\n",
    "    D = np.polyfit(time, msd, 1)[0] / 6 *1e-5 # cm^2/s\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3903ee49-c463-4e0a-a6c5-f956d99d14c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pfp_d_400 = get_diffusion_coef(pfp_msd_400, 100)\n",
    "pfp_d_500 = get_diffusion_coef(pfp_msd_500, 100)\n",
    "pfp_d_600 = get_diffusion_coef(pfp_msd_600, 100)\n",
    "lpfp_d_400 = get_diffusion_coef(lpfp_msd_400, 100)\n",
    "lpfp_d_500 = get_diffusion_coef(lpfp_msd_500, 100)\n",
    "lpfp_d_600 = get_diffusion_coef(lpfp_msd_600, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820fe7c9-cae4-4cb3-a8dd-6c2ec89a170b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import linregress\n",
    "\n",
    "R = 8.314\n",
    "temperatures = np.array([400, 500, 600])\n",
    "diff_coeffs_pfp = np.array([pfp_d_400, pfp_d_500, pfp_d_600])\n",
    "diff_coeffs_lpfp = np.array([lpfp_d_400, lpfp_d_500, lpfp_d_600])\n",
    "inv_temp = 1 / temperatures\n",
    "ln_diff_pfp = np.log(diff_coeffs_pfp)\n",
    "ln_diff_lpfp = np.log(diff_coeffs_lpfp)\n",
    "activation_energy_pfp = -linregress(inv_temp, ln_diff_pfp)[0] * R / 1000\n",
    "activation_energy_lpfp = -linregress(inv_temp, ln_diff_lpfp)[0] * R / 1000\n",
    "plt.plot(inv_temp, ln_diff_pfp, marker=\"o\", label=f'PFP {activation_energy_pfp:4.2f}kJ/mol')\n",
    "plt.plot(inv_temp, ln_diff_lpfp, marker=\"o\", label=f'LightPFP {activation_energy_lpfp:4.2f}kJ/mol')\n",
    "\n",
    "# Annotate plot\n",
    "plt.xlabel('1/T (K⁻¹)')\n",
    "plt.ylabel('ln(D) (ln(m²/s))')\n",
    "plt.title('Arrhenius Plot')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig(eval_dir/\"arrhenius.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2: Python 3.9",
   "language": "python",
   "name": "python39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
